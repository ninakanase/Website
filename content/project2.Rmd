---
title: 'Project 2: Modeling, Testing, and Predicting (SDS348)'
author: "Nina Kanase, ndk347"
date: "2020-05-01"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

## Introduction

*The dataset I have chosen for Project 2 is called "Prof_Salary," which was acquired from the R dataset list provided on the website: https://vincentarelbundock.github.io/Rdatasets/datasets.html. This dataset contains information about the nine-month academic salary for Professors in a U.S. college during the years 2008-2009 in order to monitor salary differences between male and female faculty members. This data frame contains 397 observations and 6 variables. The variable "rank" is a factor with 3 levels representing the type of Professors: Assistant Professor (AsstProf), Associate Professor (AssocProf), and Professor (Prof); the variable "discipline" is a factor with 2 levels representing the type of deparment: Theoretical Department (A) and Applied Department (B); the variable "yrs.since.phd" is a numeric that measures the years since acquiring a PhD; the variable "yrs.service" is a numeric that measures the years of teaching service at the college; the variable "sex" is a factor with 2 levels: Male and Female; and the variable "salary" is a numeric that measures the nine-month salary in dollars.*

---

```{r}

Prof_Salary <- read.csv("Professor_Salary.csv")

```


## MANOVA
```{r}
#MANOVA
manova1<-manova(cbind(salary, yrs.since.phd, yrs.service)~sex, data=Prof_Salary)
summary(manova1)

#Univariate ANOVAs
summary.aov(manova1)

#Post-hoc t-tests
pairwise.t.test(Prof_Salary$salary,Prof_Salary$sex,
                p.adj="none")
pairwise.t.test(Prof_Salary$yrs.since.phd,Prof_Salary$sex,
                p.adj="none")
pairwise.t.test(Prof_Salary$yrs.service,Prof_Salary$sex,
                p.adj="none")

#Type 1 error and bonferroni correction
(1-0.95^7)*100
0.05/7

```

*The overall MANOVA is significant as the p-value (0.005) is below 0.05, indicating that at least 1 of the 3 response variables show a mean difference across levels of sex. The univariate ANOVAs for salary (F(1,395) = 7.738, p = 0.006), years since PhD (F(1,395) = 8.942, p = 0.003), and years of service (F(1,395) = 9.562, p = 0.002) were all significant, indicating that at least one sex differs for each response variable. Because a total of 7 hypothesis tests were performed (1 MANOVA, 3 ANOVAs, and 3 t-tests), the overall type I error rate is 30.2% and the adjusted significance level used to keep the overall type I error rate at 0.05 is 0.007. Based on the post-hoc t-tests, male and females significantly differ from each other in terms of salary (p = 0.006), years since PhD (p = 0.003), and years of service (p = 0.002) after adjusting the significance level.*

---

```{r}
#MANOVA Assumptions

#Multivariate normality
ggplot(Prof_Salary, aes(x = yrs.service, y = yrs.since.phd)) +
geom_point(alpha = .5) + geom_density_2d(h=5) + facet_wrap(~sex)

#Homogeneity of covariances
covmats <- Prof_Salary %>% group_by(sex) %>% do(covs=cov(.[c(3,4,6)]))
for(i in 1:2){print(as.character(covmats$sex[i])); print(covmats$covs[i])}


```

*Based on the multivariate plot, the assumption of multivariate normality is not met as the plot does not look normal for the variables. Based on the covariance matrix, the assumption of homogeneity of within-group covariance matrices is not met either. The other assumptions of random samples, independent observations, linear relationships among DVs, no extreme univariate/multivariate outliers, and no multicollinearity are likely to have been met.*

---

## Randomization Test
```{r}
#Actual mean difference
Prof_Salary %>% group_by(sex) %>%
  summarize(means=mean(salary)) %>% 
  summarize(`mean_diff:`=diff(means))

#Permutation test
set.seed(348)
rand_salary<-vector()
for(i in 1:5000){
new<-data.frame(salary=sample(Prof_Salary$salary),sex=Prof_Salary$sex)
rand_salary[i]<-mean(new[new$sex=="Male",]$salary) - mean(new[new$sex=="Female",]$salary)}

#2-tailed P-value
mean(rand_salary > 14088.01	| rand_salary < -14088.01)

#Plot of null distribution/test-statitic
{hist(rand_salary); abline(v = -14088.01, col="red")}

```

*A randomization test was performed to test the association between salary and sex to see if there was a difference in mean salary between males and females. The null hypothesis states that the mean salary is the same for males and females, while the alternative hypothesis states that the mean salary is different for males and females. The actual mean salary difference between males and females is $14,088.01. The p-value for the permutation test is 0.005, which is significant since it is less than 0.05. The plot of the null distribution shows the actual mean difference (red line) at the tail end of the plot, which looks strange if there was actually no relationship between the variables. The probability of observing a mean difference as big as 14,088.01 under the randomization distribution is 0.005, thereby rejecting the null hypothesis.*

---

## Linear Regression Model
```{r}

Prof_Salary$yrs.service_c <- Prof_Salary$yrs.service - mean(Prof_Salary$yrs.service, na.rm=T)
fit<-lm(salary ~ yrs.service_c*discipline, data=Prof_Salary)
summary(fit)

```

*The intercept coefficient shows that the predicted salary for the reference group, which is discipline A, is $107,317.9 for average years of service. The "yrs.service_c" coefficient represents the slope, where every 1 additional year of service in discipline A results in the salary increasing by $526.8. The "discipline B" coefficient shows that the salary in discipline B is $13,102.5 higher than in discipline A for average years of service. The "yrs.service_c:disciplineB" coefficient shows that discipline B's slope is bigger by a factor of $695.2 compared to discipline A's slope for the effect of average years of serivice on salary.*

---

```{r}
#Linear Regression ggplot
fit %>% ggplot(aes(yrs.service_c, salary, color=discipline))+ geom_point() + geom_smooth(method="lm",se=F)

```

*The reggresion plot shows that there is a significant interaction, where discipline B has a steeper slope than discpline A. Therefore, there is a stronger relationship between salary and discipline B.*

---


```{r}
#Assumptions of Linear Regression

#Linearity
resids<-lm(salary~yrs.service_c*discipline, data=Prof_Salary)$residuals
resids<-fit$residuals
fitvals<-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color='red')

#Normality
shapiro.test(resids)

#Homoskedasticity
library(lmtest)
library(sandwich)
bptest(fit)

```

*The scatterplot of the fitted values and the residuals shows that there is a linear relationship between each predictor and response variable. The p-value for the Shapiro-Wilk normality test is less than 0.05 (3.482e-08), rejecting the null that the true distribution is normal. The Breusch-Pagan test shows that homoskedasticity is not met as the p-value is less than 0.05 (0.001), rejecting the null hypothesis that the data is homoskedastic. Therefore, the linearity assumption is met while the normality and homoskedasticity assumptions are not met.*

---


```{r}
#Regression with robust SE
summary(fit)
coeftest(fit, vcov=vcovHC(fit))

```

*When recomputing the regression using heteroskedasticity robust standard errors, the p-values increased for yrs.service_c (0.0005 to 0.003), disciplineB (4.4e-06 to 1.033e-05), and yrs.service_c:disciplineB (0.001 to 0.008), while the p-value for the intercept remained about the same (< 2e-16 to < 2.2e-16). All slope values remained the same and are significant as their corresponding p-values are less than 0.05. The proportion of the variation in the outcome explained by this model is 0.1795.*

---

## Bootstrapped Standard Errors
```{r}

set.seed(348)

samp_distn<-replicate(5000, {
boot_dat <- sample_frac(Prof_Salary, replace=T)
fit<-lm(salary ~ yrs.service_c*discipline, data=boot_dat)
coef(fit)
})
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)

```

*The bootstrap standard errors via observation resampling were calculated for the intercept (2226.96), yrs.service_c (176.70), disciplineB (2920.19), and yrs.service_c:discplineB (259.53). Compared to these values, the original standard errors are lower for the intercept (2076.80), yrs.service_c (150.10), disciplineB (2813.70), and yrs.service_c:discplineB (215.90) as more assumptions are made. Compared to the original values, the bootstrap standard errors are closer in value to the robust standard errors for the intercept (2215.51), yrs.service_c (178.83), disciplineB (2932.43), and yrs.service_c:discplineB (261.15). A higher standard error indicates a higher p-value.*

---

## Logistic Regression
```{r}
#Coefficient estimates
fit1<-glm(sex ~ salary+rank, data=Prof_Salary, family=binomial(link="logit"))
coeftest(fit1)
exp(coef(fit1))

```

*The intercept coefficient shows that there is not a significant effect of being an associate professor on sex (p = 0.53); the odds of being male for associate professors is 1.73. When controlling for rank, there is not a signficant effect of salary on sex (p = 0.17); for every 1 unit increase in salary, the odds of being male increases by a factor of 1.00 when controlling for rank. When controlling for salary, there is not a significant effect of being an assistant professor (p = 0.85) or being a professor (p = 0.24) on sex. When controlling for salary, the odds of being male for an assistant professor rank is 1.10 times the odds of being male for an associate professor rank. When controlling for salary, the odds of being male for a professor rank is 1.77 times the odds of being male for an associate professor rank.*

---

```{r}
#Confusion matrix
prob1<-predict(fit1,type="response")
table(predict=as.numeric(prob1>.5),truth=Prof_Salary$sex) %>% addmargins

#Density plot of logit
Prof_Salary$logit<-predict(fit1)
Prof_Salary$sex<-factor(Prof_Salary$sex,levels=c("Male","Female"))
ggplot(Prof_Salary,aes(logit, fill=sex)) + geom_density(alpha=.3) +
  geom_vline(xintercept=0,lty=2)

#ROC Curve
library(plotROC)
ROCplot<-ggplot(Prof_Salary)+geom_roc(aes(d=sex,m=prob1), n.cuts=0)
ROCplot

#AUC
calc_auc(ROCplot)

```

*Based on the confusion matrix, the sensitivity is 1 and the specificity is 0. The AUC is calculated to be 0.645, which is poor. The ROC plot and AUC indicate that it is hard to predict sex from salary and rank.*

---

```{r}

class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

```

```{r}
#10-Fold CV
set.seed(1234)
k=10

data<-Prof_Salary[sample(nrow(Prof_Salary)),]
folds<-cut(seq(1:nrow(Prof_Salary)),breaks=k,labels=F)

diags<-NULL
for(i in 1:k){

  train<-data[folds!=i,] 
  test<-data[folds==i,]
  
  truth<-test$sex
  
  fit<-glm(sex~salary+rank, data=train,family="binomial")
  
  probs<-predict(fit,newdata = test,type="response")
  
  diags<-rbind(diags,class_diag(probs,truth))
}

summarize_all(diags,mean)

```

*When predicting out of sample, the AUC decreased to 0.614. Therefore, the performance of the model is slightly worse out of sample and the drop in AUC indicates that the model is overfitting. The accuracy is 0.902, the sensitivity is still 1, and the specificity is still 0.*

---

## LASSO Regression
```{r}

library(glmnet)
set.seed(1234)

fit2 <- glm(sex~., data=Prof_Salary, family=binomial(link="logit"))
x<-model.matrix(fit2)[,-1]
x<-scale(x)
y<-as.matrix(Prof_Salary$sex)

cv <- cv.glmnet(x,y,family="binomial")
lasso<-glmnet(x,y,family="binomial",lambda=cv$lambda.min)
coef(lasso)

lasso_prob<-predict(lasso, newx=x, type="response")
class_diag(lasso_prob,Prof_Salary$sex)

```

*The non-zero coefficient estimates are Intercept, rankProf, yrs.service, and salary. The AUC after performing a Lasso regression is 0.678, which is about 0.03 higher than the AUC from the logistic regression model (0.645). Therefore, this model is performing better, although the AUC is still poor.*

---

```{r}
#10-Fold CV WITH LASSO
set.seed(1234)
k=10

Prof_Salary_new <- Prof_Salary %>% 
  mutate(professor=ifelse(rank=="Prof",1,0))%>% 
  select(sex, professor, yrs.service, salary)

data<-Prof_Salary_new[sample(nrow(Prof_Salary_new)),]
folds<-cut(seq(1:nrow(Prof_Salary_new)),breaks=k,labels=F)

diags<-NULL
for(i in 1:k){

  train<-data[folds!=i,] 
  test<-data[folds==i,]
  
  truth<-test$sex
  
  fit<-glm(sex~professor+yrs.service+salary, data=train, family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  
  diags<-rbind(diags,class_diag(probs,truth))
}

summarize_all(diags,mean)

```

*After performing a 10-fold CV using the lasso regression, the AUC is 0.641. This is still poor, although it is about 0.3 higher than the AUC of the 10-fold CV using the logistic regression (0.614). Therefore, this model is more accurate at making out-of-sample predictions.*

---
